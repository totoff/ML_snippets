{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VGG_Restnet_Inception_TransferLearning.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"U4lBvfp3ppa8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"93b2c6ab-fa12-4576-b963-743a8ed27ed6","executionInfo":{"status":"ok","timestamp":1565946039529,"user_tz":-120,"elapsed":8812,"user":{"displayName":"Christophe Grihon","photoUrl":"","userId":"17281359019211225799"}}},"source":["!pip install -U -q PyDrive"],"execution_count":1,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 993kB 1.4MB/s \n","\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C5pi63JmqCa4","colab_type":"code","colab":{}},"source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# Authentification Google\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9RyyRTVuqFxn","colab_type":"code","colab":{}},"source":["# Download du fichier\n","\n","downloaded = drive.CreateFile({'id': '1TQ8lA7QGRnFn_-3t7mBWOisTvl4802gs'})\n","downloaded.GetContentFile('dog.jpg')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HW-lSSb1pe8-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":379},"outputId":"b21bac70-76ae-4f62-d34a-fb23df615cda","executionInfo":{"status":"ok","timestamp":1565946207437,"user_tz":-120,"elapsed":17439,"user":{"displayName":"Christophe Grihon","photoUrl":"","userId":"17281359019211225799"}}},"source":["# example of using a pre-trained model as a classifier\n","from keras.preprocessing.image import load_img\n","from keras.preprocessing.image import img_to_array\n","from keras.applications.vgg16 import preprocess_input\n","from keras.applications.vgg16 import decode_predictions\n","from keras.applications.vgg16 import VGG16\n","# load an image from file\n","image = load_img('dog.jpg', target_size=(224, 224))\n","# convert the image pixels to a numpy array\n","image = img_to_array(image)\n","# reshape data for the model\n","image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n","# prepare the image for the VGG model\n","image = preprocess_input(image)\n","# load the model\n","model = VGG16()\n","# predict the probability across all output classes\n","yhat = model.predict(image)\n","# convert the probabilities to class labels\n","label = decode_predictions(yhat)\n","# retrieve the most likely result, e.g. highest probability\n","label = label[0][0]\n","# print the classification\n","print('%s (%.2f%%)' % (label[1], label[2]*100))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","WARNING: Logging before flag parsing goes to stderr.\n","W0816 09:03:12.190698 139816260560768 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0816 09:03:12.219351 139816260560768 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0816 09:03:12.225367 139816260560768 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0816 09:03:12.260866 139816260560768 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n","553467904/553467096 [==============================] - 7s 0us/step\n"],"name":"stdout"},{"output_type":"stream","text":["W0816 09:03:20.613561 139816260560768 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","W0816 09:03:20.615169 139816260560768 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n","40960/35363 [==================================] - 0s 0us/step\n","Doberman (33.59%)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gPLYRIPSqvB7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"e5f5944a-761a-47be-ac0d-0e17bb2a0798","executionInfo":{"status":"ok","timestamp":1565946285773,"user_tz":-120,"elapsed":3346,"user":{"displayName":"Christophe Grihon","photoUrl":"","userId":"17281359019211225799"}}},"source":["# example of using the vgg16 model as a feature extraction model\n","from keras.preprocessing.image import load_img\n","from keras.preprocessing.image import img_to_array\n","from keras.applications.vgg16 import preprocess_input\n","from keras.applications.vgg16 import decode_predictions\n","from keras.applications.vgg16 import VGG16\n","from keras.models import Model\n","from pickle import dump\n","# load an image from file\n","image = load_img('dog.jpg', target_size=(224, 224))\n","# convert the image pixels to a numpy array\n","image = img_to_array(image)\n","# reshape data for the model\n","image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n","# prepare the image for the VGG model\n","image = preprocess_input(image)\n","# load model\n","model = VGG16()\n","# remove the output layer\n","model.layers.pop()\n","model = Model(inputs=model.inputs, outputs=model.layers[-1].output)\n","# get extracted features\n","features = model.predict(image)\n","print(features.shape)\n","# save to file\n","dump(features, open('dog.pkl', 'wb'))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["(1, 4096)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FkgeRmZSrABg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"843f7b3b-99a1-466a-9281-d64d2cd16e26","executionInfo":{"status":"ok","timestamp":1565946297797,"user_tz":-120,"elapsed":2134,"user":{"displayName":"Christophe Grihon","photoUrl":"","userId":"17281359019211225799"}}},"source":["%ls"],"execution_count":6,"outputs":[{"output_type":"stream","text":["adc.json  dog.jpg  dog.pkl  ipykernel_launcher.py_plot.png  \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nLuEd6RerDRB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":971},"outputId":"b117a565-233c-415d-e2a0-ab5c0852ebf2","executionInfo":{"status":"ok","timestamp":1565946402773,"user_tz":-120,"elapsed":2612,"user":{"displayName":"Christophe Grihon","photoUrl":"","userId":"17281359019211225799"}}},"source":["# example of tending the vgg16 model\n","from keras.applications.vgg16 import VGG16\n","from keras.models import Model\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","# load model without classifier layers\n","model = VGG16(include_top=False, input_shape=(300, 300, 3))\n","# add new classifier layers\n","flat1 = Flatten()(model.outputs)\n","class1 = Dense(1024, activation='relu')(flat1)\n","output = Dense(10, activation='softmax')(class1)\n","# define new model\n","model = Model(inputs=model.inputs, outputs=output)\n","# summarize\n","model.summary()\n","# ..."],"execution_count":8,"outputs":[{"output_type":"stream","text":["Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 1s 0us/step\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_3 (InputLayer)         (None, 300, 300, 3)       0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 300, 300, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 300, 300, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 150, 150, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 150, 150, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 150, 150, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 75, 75, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 75, 75, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 75, 75, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 75, 75, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 37, 37, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 37, 37, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 37, 37, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 37, 37, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 18, 18, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 18, 18, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 41472)             0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1024)              42468352  \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 10)                10250     \n","=================================================================\n","Total params: 57,193,290\n","Trainable params: 57,193,290\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rmtx29TDrGd2","colab_type":"code","colab":{}},"source":["# load model without classifier layers\n","model = VGG16(include_top=False, input_shape=(300, 300, 3))\n","# mark loaded layers as not trainable\n","for layer in model.layers:\n","\tlayer.trainable = False"],"execution_count":0,"outputs":[]}]}