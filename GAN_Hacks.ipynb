{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GAN_Hacks.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"BmGI0GGrtqWW","colab_type":"text"},"source":["**Downsample Using Strided Convolutions**"]},{"cell_type":"code","metadata":{"id":"uPUUxqSftjHr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":361},"outputId":"a931a570-3b3f-4183-9105-097ab8ed321d","executionInfo":{"status":"ok","timestamp":1567339547872,"user_tz":-120,"elapsed":2532,"user":{"displayName":"Christophe Grihon","photoUrl":"","userId":"17281359019211225799"}}},"source":["# example of downsampling with strided convolutions\n","from keras.models import Sequential\n","from keras.layers import Conv2D\n","# define model\n","model = Sequential()\n","model.add(Conv2D(64, kernel_size=(3,3), strides=(2,2), padding='same', input_shape=(64,64,3)))\n","# summarize model\n","model.summary()"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","WARNING: Logging before flag parsing goes to stderr.\n","W0901 12:05:47.423182 140532818683776 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0901 12:05:47.461007 140532818683776 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0901 12:05:47.469752 140532818683776 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 32, 32, 64)        1792      \n","=================================================================\n","Total params: 1,792\n","Trainable params: 1,792\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rjz52lmDuD9R","colab_type":"text"},"source":["**Upsample Using Strided Convolutions**"]},{"cell_type":"code","metadata":{"id":"wFK3V5tht1Pg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":197},"outputId":"499b8e94-bd3b-4b29-8748-756e97806fc4","executionInfo":{"status":"ok","timestamp":1567339659197,"user_tz":-120,"elapsed":1529,"user":{"displayName":"Christophe Grihon","photoUrl":"","userId":"17281359019211225799"}}},"source":["# example of upsampling with strided convolutions\n","from keras.models import Sequential\n","from keras.layers import Conv2DTranspose\n","# define model\n","model = Sequential()\n","model.add(Conv2DTranspose(64, kernel_size=(4,4), strides=(2,2), padding='same', input_shape=(64,64,3)))\n","# summarize model\n","model.summary()"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_transpose_1 (Conv2DTr (None, 128, 128, 64)      3136      \n","=================================================================\n","Total params: 3,136\n","Trainable params: 3,136\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8Fwvkk2Fu0o_","colab_type":"text"},"source":["**Use LeakyReLU**"]},{"cell_type":"code","metadata":{"id":"RWwRWUokuTli","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":233},"outputId":"9187b944-d273-4822-a5f3-2b6a6019d408","executionInfo":{"status":"ok","timestamp":1567339812502,"user_tz":-120,"elapsed":1511,"user":{"displayName":"Christophe Grihon","photoUrl":"","userId":"17281359019211225799"}}},"source":["# example of using leakyrelu in a discriminator model\n","from keras.models import Sequential\n","from keras.layers import Conv2D\n","from keras.layers import BatchNormalization\n","from keras.layers import LeakyReLU\n","# define model\n","model = Sequential()\n","model.add(Conv2D(64, kernel_size=(3,3), strides=(2,2), padding='same', input_shape=(64,64,3)))\n","model.add(LeakyReLU(0.2))\n","# summarize model\n","model.summary()"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_2 (Conv2D)            (None, 32, 32, 64)        1792      \n","_________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)    (None, 32, 32, 64)        0         \n","=================================================================\n","Total params: 1,792\n","Trainable params: 1,792\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JDxI2w60vCbV","colab_type":"text"},"source":["**Use Batch Normalization**"]},{"cell_type":"code","metadata":{"id":"lDCiFh5cu5BK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":397},"outputId":"1952b63d-e486-464b-9b70-0bd39fa3c51a","executionInfo":{"status":"ok","timestamp":1567339871697,"user_tz":-120,"elapsed":5218,"user":{"displayName":"Christophe Grihon","photoUrl":"","userId":"17281359019211225799"}}},"source":["# example of using batch norm in a discriminator model\n","from keras.models import Sequential\n","from keras.layers import Conv2D\n","from keras.layers import BatchNormalization\n","from keras.layers import LeakyReLU\n","# define model\n","model = Sequential()\n","model.add(Conv2D(64, kernel_size=(3,3), strides=(2,2), padding='same', input_shape=(64,64,3)))\n","model.add(BatchNormalization())\n","model.add(LeakyReLU(0.2))\n","# summarize model\n","model.summary()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["W0901 12:11:06.689993 140532818683776 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","W0901 12:11:06.690901 140532818683776 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","W0901 12:11:10.339999 140532818683776 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_3 (Conv2D)            (None, 32, 32, 64)        1792      \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n","_________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)    (None, 32, 32, 64)        0         \n","=================================================================\n","Total params: 2,048\n","Trainable params: 1,920\n","Non-trainable params: 128\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6dmR_CJHw3d4","colab_type":"text"},"source":["**Use Gaussian Weight Initialization**"]},{"cell_type":"code","metadata":{"id":"2Krd19rnvGj2","colab_type":"code","colab":{}},"source":["# example of gaussian weight initialization in a generator model\n","from keras.models import Sequential\n","from keras.layers import Conv2DTranspose\n","from keras.initializers import RandomNormal\n","# define model\n","model = Sequential()\n","init = RandomNormal(mean=0.0, stddev=0.02)\n","model.add(Conv2DTranspose(64, kernel_size=(4,4), strides=(2,2), padding='same', kernel_initializer=init, input_shape=(64,64,3)))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ll1iF6IaxCTg","colab_type":"text"},"source":["**Use Adam Stochastic Gradient Descent**\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"aENZ-spUwxkq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":127},"outputId":"35ddc0fa-8db6-4876-d4d5-d1677c12b1ac","executionInfo":{"status":"ok","timestamp":1567340424097,"user_tz":-120,"elapsed":1541,"user":{"displayName":"Christophe Grihon","photoUrl":"","userId":"17281359019211225799"}}},"source":["# example of using adam when training a discriminator model\n","from keras.models import Sequential\n","from keras.layers import Conv2D\n","from keras.optimizers import Adam\n","# define model\n","model = Sequential()\n","model.add(Conv2D(64, kernel_size=(3,3), strides=(2,2), padding='same', input_shape=(64,64,3)))\n","# compile model\n","opt = Adam(lr=0.0002, beta_1=0.5)\n","model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"],"execution_count":6,"outputs":[{"output_type":"stream","text":["W0901 12:20:22.711935 140532818683776 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0901 12:20:22.721267 140532818683776 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"9k4mT2mixoQX","colab_type":"text"},"source":["**Use a Gaussian Latent Space**"]},{"cell_type":"code","metadata":{"id":"VCZZSh54xOU8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"4c95601e-9cf2-42f5-f29e-a2d7614b55ef","executionInfo":{"status":"ok","timestamp":1567340568236,"user_tz":-120,"elapsed":1553,"user":{"displayName":"Christophe Grihon","photoUrl":"","userId":"17281359019211225799"}}},"source":["# example of sampling from a gaussian latent space\n","from numpy.random import randn\n","\n","# generate points in latent space as input for the generator\n","def generate_latent_points(latent_dim, n_samples):\n","\t# generate points in the latent space\n","\tx_input = randn(latent_dim * n_samples)\n","\t# reshape into a batch of inputs for the network\n","\tx_input = x_input.reshape((n_samples, latent_dim))\n","\treturn x_input\n","\n","# size of latent space\n","n_dim = 100\n","# number of samples to generate\n","n_samples = 500\n","# generate samples\n","samples = generate_latent_points(n_dim, n_samples)\n","# summarize\n","print(samples.shape, samples.mean(), samples.std())"],"execution_count":7,"outputs":[{"output_type":"stream","text":["(500, 100) -0.0004093096661395749 1.002743971393144\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9p0Pus7mx_GD","colab_type":"text"},"source":["**Use Label Smoothing**"]},{"cell_type":"code","metadata":{"id":"mzq6ItWPxxgx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"fbb20aad-b6dc-4ca7-d634-a270811ba7ab","executionInfo":{"status":"ok","timestamp":1567340703109,"user_tz":-120,"elapsed":1565,"user":{"displayName":"Christophe Grihon","photoUrl":"","userId":"17281359019211225799"}}},"source":["# example of positive label smoothing\n","from numpy import ones\n","from numpy.random import random\n","\n","# example of smoothing class=1 to [0.7, 1.2]\n","def smooth_positive_labels(y):\n","\treturn y - 0.3 + (random(y.shape) * 0.5)\n","\n","\n","# generate 'real' class labels (1)\n","n_samples = 1000\n","y = ones((n_samples, 1))\n","# smooth labels\n","y = smooth_positive_labels(y)\n","# summarize smooth labels\n","print(y.shape, y.min(), y.max())"],"execution_count":8,"outputs":[{"output_type":"stream","text":["(1000, 1) 0.7005846445886794 1.1986152874294862\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RVf10mWAyScA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"c5254bf7-63a1-4e0c-d841-414a556cd574","executionInfo":{"status":"ok","timestamp":1567340740449,"user_tz":-120,"elapsed":1537,"user":{"displayName":"Christophe Grihon","photoUrl":"","userId":"17281359019211225799"}}},"source":["# example of negative label smoothing\n","from numpy import zeros\n","from numpy.random import random\n","\n","# example of smoothing class=0 to [0.0, 0.3]\n","def smooth_negative_labels(y):\n","\treturn y + random(y.shape) * 0.3\n","\n","# generate 'fake' class labels (0)\n","n_samples = 1000\n","y = zeros((n_samples, 1))\n","# smooth labels\n","y = smooth_negative_labels(y)\n","# summarize smooth labels\n","print(y.shape, y.min(), y.max())"],"execution_count":9,"outputs":[{"output_type":"stream","text":["(1000, 1) 0.00036696778897752356 0.2996596053952072\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nd07P9yQywD6","colab_type":"text"},"source":["**Use Noisy Labels**"]},{"cell_type":"code","metadata":{"id":"Y450zqTQybj5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"174f28d5-3d47-4dd2-bc50-e33b26a074b0","executionInfo":{"status":"ok","timestamp":1567340907642,"user_tz":-120,"elapsed":1537,"user":{"displayName":"Christophe Grihon","photoUrl":"","userId":"17281359019211225799"}}},"source":["# example of noisy labels\n","from numpy import ones\n","from numpy import zeros\n","from numpy.random import choice\n","\n","# randomly flip some labels\n","def noisy_labels(y, p_flip):\n","\t# determine the number of labels to flip\n","\tn_select = int(p_flip * y.shape[0])\n","\t# choose labels to flip\n","\tflip_ix = choice([i for i in range(y.shape[0])], size=n_select)\n","\t# invert the labels in place\n","\ty[flip_ix] = 1 - y[flip_ix]\n","\treturn y\n","\n","# generate 'real' class labels (1)\n","n_samples = 1000\n","y = ones((n_samples, 1))\n","# flip labels with 5% probability\n","y = noisy_labels(y, 0.05)\n","# summarize labels\n","print(y.sum())\n","\n","# generate 'fake' class labels (0)\n","y = zeros((n_samples, 1))\n","# flip labels with 5% probability\n","y = noisy_labels(y, 0.05)\n","# summarize labels\n","print(y.sum())"],"execution_count":10,"outputs":[{"output_type":"stream","text":["952.0\n","48.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NEfyQ417zEYN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}