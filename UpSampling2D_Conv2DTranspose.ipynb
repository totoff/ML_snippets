{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"UpSampling2D_Conv2DTranspose.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"HD9W1v5Qz4aV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":577},"outputId":"b132a828-8bc4-42b4-9ec2-56edb12a5c78","executionInfo":{"status":"ok","timestamp":1567341411070,"user_tz":-120,"elapsed":3227,"user":{"displayName":"Christophe Grihon","photoUrl":"","userId":"17281359019211225799"}}},"source":["# example of using the upsampling layer\n","from numpy import asarray\n","from keras.models import Sequential\n","from keras.layers import UpSampling2D\n","# define input data\n","X = asarray([[1, 2],\n","\t\t\t [3, 4]])\n","# show input data for context\n","print(X)\n","# reshape input data into one sample a sample with a channel\n","X = X.reshape((1, 2, 2, 1))\n","# define model\n","model = Sequential()\n","model.add(UpSampling2D(input_shape=(2, 2, 1)))\n","# summarize the model\n","model.summary()\n","# make a prediction with the model\n","yhat = model.predict(X)\n","# reshape output to remove channel to make printing easier\n","yhat = yhat.reshape((4, 4))\n","# summarize output\n","print(yhat)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","WARNING: Logging before flag parsing goes to stderr.\n","W0901 12:36:50.117535 139862649472896 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0901 12:36:50.150550 139862649472896 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0901 12:36:50.169517 139862649472896 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n","\n","W0901 12:36:50.173334 139862649472896 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","W0901 12:36:50.176312 139862649472896 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","W0901 12:36:50.180208 139862649472896 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["[[1 2]\n"," [3 4]]\n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","up_sampling2d_1 (UpSampling2 (None, 4, 4, 1)           0         \n","=================================================================\n","Total params: 0\n","Trainable params: 0\n","Non-trainable params: 0\n","_________________________________________________________________\n","[[1. 1. 2. 2.]\n"," [1. 1. 2. 2.]\n"," [3. 3. 4. 4.]\n"," [3. 3. 4. 4.]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m388EO9c09CB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":361},"outputId":"070a94bb-0a0f-41b2-d7cc-faea0056af0c","executionInfo":{"status":"ok","timestamp":1567341570204,"user_tz":-120,"elapsed":848,"user":{"displayName":"Christophe Grihon","photoUrl":"","userId":"17281359019211225799"}}},"source":["# example of using the upsampling layer\n","from numpy import asarray\n","from keras.models import Sequential\n","from keras.layers import UpSampling2D\n","# define input data\n","X = asarray([[1, 2],\n","\t\t\t [3, 4]])\n","# show input data for context\n","print(X)\n","# reshape input data into one sample a sample with a channel\n","X = X.reshape((1, 2, 2, 1))\n","# define model\n","model = Sequential()\n","# example of using bilinear interpolation when upsampling\n","model.add(UpSampling2D(input_shape=(2, 2, 1),interpolation='bilinear'))\n","# summarize the model\n","model.summary()\n","# make a prediction with the model\n","yhat = model.predict(X)\n","# reshape output to remove channel to make printing easier\n","yhat = yhat.reshape((4, 4))\n","# summarize output\n","print(yhat)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["W0901 12:39:29.473626 139862649472896 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2241: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["[[1 2]\n"," [3 4]]\n","Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","up_sampling2d_3 (UpSampling2 (None, 4, 4, 1)           0         \n","=================================================================\n","Total params: 0\n","Trainable params: 0\n","Non-trainable params: 0\n","_________________________________________________________________\n","[[1.  1.5 2.  2. ]\n"," [2.  2.5 3.  3. ]\n"," [3.  3.5 4.  4. ]\n"," [3.  3.5 4.  4. ]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fKZVGQiq1mTH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":305},"outputId":"22b9427b-eb2e-4167-8e19-ad1eed9a1687","executionInfo":{"status":"ok","timestamp":1567341699676,"user_tz":-120,"elapsed":481,"user":{"displayName":"Christophe Grihon","photoUrl":"","userId":"17281359019211225799"}}},"source":["# example of using upsampling in a simple generator model\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Reshape\n","from keras.layers import UpSampling2D\n","from keras.layers import Conv2D\n","# define model\n","model = Sequential()\n","# define input shape, output enough activations for for 128 5x5 image\n","model.add(Dense(128 * 5 * 5, input_dim=100))\n","# reshape vector of activations into 128 feature maps with 5x5\n","model.add(Reshape((5, 5, 128)))\n","# double input from 128 5x5 to 1 10x10 feature map\n","model.add(UpSampling2D())\n","# fill in detail in the upsampled feature maps and output a single image\n","model.add(Conv2D(1, (3,3), padding='same'))\n","# summarize model\n","model.summary()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 3200)              323200    \n","_________________________________________________________________\n","reshape_1 (Reshape)          (None, 5, 5, 128)         0         \n","_________________________________________________________________\n","up_sampling2d_4 (UpSampling2 (None, 10, 10, 128)       0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 10, 10, 1)         1153      \n","=================================================================\n","Total params: 324,353\n","Trainable params: 324,353\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EGQLLVi72F_j","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":305},"outputId":"eca02fef-3f62-40ec-9477-68a256fcf654","executionInfo":{"status":"ok","timestamp":1567342366992,"user_tz":-120,"elapsed":732,"user":{"displayName":"Christophe Grihon","photoUrl":"","userId":"17281359019211225799"}}},"source":["# example of using the transpose convolutional layer\n","from numpy import asarray\n","from keras.models import Sequential\n","from keras.layers import Conv2DTranspose\n","# define input data\n","X = asarray([[1, 2],\n","\t\t\t [3, 4]])\n","# show input data for context\n","print(X)\n","# reshape input data into one sample a sample with a channel\n","X = X.reshape((1, 2, 2, 1))\n","# define model\n","model = Sequential()\n","model.add(Conv2DTranspose(1, (1,1), strides=(2,2), input_shape=(2, 2, 1)))\n","# summarize the model\n","model.summary()\n","# define weights that they do nothing\n","weights = [asarray([[[[1]]]]), asarray([0])]\n","# store the weights in the model\n","model.set_weights(weights)\n","# make a prediction with the model\n","yhat = model.predict(X)\n","# reshape output to remove channel to make printing easier\n","yhat = yhat.reshape((4, 4))\n","# summarize output\n","print(yhat)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["[[1 2]\n"," [3 4]]\n","Model: \"sequential_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_transpose_1 (Conv2DTr (None, 4, 4, 1)           2         \n","=================================================================\n","Total params: 2\n","Trainable params: 2\n","Non-trainable params: 0\n","_________________________________________________________________\n","[[1. 0. 2. 0.]\n"," [0. 0. 0. 0.]\n"," [3. 0. 4. 0.]\n"," [0. 0. 0. 0.]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kY77g4J84o2b","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":269},"outputId":"22317abb-e8e9-455a-9ec9-184ad5eb15d2","executionInfo":{"status":"ok","timestamp":1567342691584,"user_tz":-120,"elapsed":472,"user":{"displayName":"Christophe Grihon","photoUrl":"","userId":"17281359019211225799"}}},"source":["# example of using transpose conv in a simple generator model\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Reshape\n","from keras.layers import Conv2DTranspose\n","from keras.layers import Conv2D\n","# define model\n","model = Sequential()\n","# define input shape, output enough activations for for 128 5x5 image\n","model.add(Dense(128 * 5 * 5, input_dim=100))\n","# reshape vector of activations into 128 feature maps with 5x5\n","model.add(Reshape((5, 5, 128)))\n","# double input from 128 5x5 to 1 10x10 feature map\n","model.add(Conv2DTranspose(1, (3,3), strides=(2,2), padding='same'))\n","# summarize model\n","model.summary()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_2 (Dense)              (None, 3200)              323200    \n","_________________________________________________________________\n","reshape_2 (Reshape)          (None, 5, 5, 128)         0         \n","_________________________________________________________________\n","conv2d_transpose_2 (Conv2DTr (None, 10, 10, 1)         1153      \n","=================================================================\n","Total params: 324,353\n","Trainable params: 324,353\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]}]}