{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11094352 0.20772456 0.3038872  0.4000682  0.49691436 0.5951052\n 0.69537634 0.79854804 0.9055575 ]\n"
     ]
    }
   ],
   "source": [
    "# lstm autoencoder recreate sequence\n",
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.utils import plot_model\n",
    "# define input sequence\n",
    "sequence = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "# reshape input into [samples, timesteps, features]\n",
    "n_in = len(sequence)\n",
    "sequence = sequence.reshape((1, n_in, 1))\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', input_shape=(n_in,1)))\n",
    "model.add(RepeatVector(n_in))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(sequence, sequence, epochs=300, verbose=0)\n",
    "plot_model(model, show_shapes=True, to_file='reconstruct_lstm_autoencoder.png')\n",
    "# demonstrate recreation\n",
    "yhat = model.predict(sequence, verbose=0)\n",
    "print(yhat[0,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16718303 0.2907621  0.4035556  0.5089474  0.6090384  0.7054243\n 0.79941404 0.8921318 ]\n"
     ]
    }
   ],
   "source": [
    "# lstm autoencoder predict sequence\n",
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.utils import plot_model\n",
    "# define input sequence\n",
    "seq_in = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "# reshape input into [samples, timesteps, features]\n",
    "n_in = len(seq_in)\n",
    "seq_in = seq_in.reshape((1, n_in, 1))\n",
    "# prepare output sequence\n",
    "seq_out = seq_in[:, 1:, :]\n",
    "n_out = n_in - 1\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', input_shape=(n_in,1)))\n",
    "model.add(RepeatVector(n_out))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "plot_model(model, show_shapes=True, to_file='predict_lstm_autoencoder.png')\n",
    "# fit model\n",
    "model.fit(seq_in, seq_out, epochs=300, verbose=0)\n",
    "# demonstrate prediction\n",
    "yhat = model.predict(seq_in, verbose=0)\n",
    "print(yhat[0,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[0.10524049],\n        [0.19997554],\n        [0.29829857],\n        [0.39866695],\n        [0.50012314],\n        [0.6010276 ],\n        [0.70053655],\n        [0.7997442 ],\n        [0.8997517 ]]], dtype=float32), array([[[0.17198311],\n        [0.29647064],\n        [0.40683484],\n        [0.5062819 ],\n        [0.60210896],\n        [0.6980366 ],\n        [0.7970193 ],\n        [0.901843  ]]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# lstm autoencoder reconstruct and predict sequence\n",
    "from numpy import array\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.utils import plot_model\n",
    "# define input sequence\n",
    "seq_in = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "# reshape input into [samples, timesteps, features]\n",
    "n_in = len(seq_in)\n",
    "seq_in = seq_in.reshape((1, n_in, 1))\n",
    "# prepare output sequence\n",
    "seq_out = seq_in[:, 1:, :]\n",
    "n_out = n_in - 1\n",
    "# define encoder\n",
    "visible = Input(shape=(n_in,1))\n",
    "encoder = LSTM(100, activation='relu')(visible)\n",
    "# define reconstruct decoder\n",
    "decoder1 = RepeatVector(n_in)(encoder)\n",
    "decoder1 = LSTM(100, activation='relu', return_sequences=True)(decoder1)\n",
    "decoder1 = TimeDistributed(Dense(1))(decoder1)\n",
    "# define predict decoder\n",
    "decoder2 = RepeatVector(n_out)(encoder)\n",
    "decoder2 = LSTM(100, activation='relu', return_sequences=True)(decoder2)\n",
    "decoder2 = TimeDistributed(Dense(1))(decoder2)\n",
    "# tie it together\n",
    "model = Model(inputs=visible, outputs=[decoder1, decoder2])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "plot_model(model, show_shapes=True, to_file='composite_lstm_autoencoder.png')\n",
    "# fit model\n",
    "model.fit(seq_in, [seq_in,seq_out], epochs=300, verbose=0)\n",
    "# demonstrate prediction\n",
    "yhat = model.predict(seq_in, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100)\n[[0.         0.         0.04047523 0.         0.0510991  0.05057862\n  0.04730454 0.         0.02609361 0.         0.07832593 0.07288182\n  0.07915495 0.         0.         0.         0.         0.\n  0.         0.         0.07989946 0.         0.         0.03689558\n  0.07974971 0.06056995 0.07075986 0.         0.06812122 0.\n  0.         0.04283774 0.0671531  0.         0.05396653 0.00061027\n  0.         0.         0.09573343 0.         0.03644436 0.\n  0.03504974 0.         0.         0.         0.029341   0.\n  0.         0.         0.         0.05517212 0.         0.09759364\n  0.         0.02508017 0.         0.07132178 0.         0.00128413\n  0.04537169 0.04972531 0.         0.         0.         0.02398403\n  0.07777508 0.09052594 0.00165794 0.         0.         0.\n  0.         0.07783865 0.09099393 0.08997516 0.         0.041105\n  0.04566029 0.         0.08160834 0.         0.00291906 0.06397757\n  0.06541616 0.02318096 0.         0.         0.09754752 0.04336731\n  0.04114583 0.10843901 0.         0.         0.         0.\n  0.         0.         0.         0.06456561]]\n"
     ]
    }
   ],
   "source": [
    "# lstm autoencoder recreate sequence\n",
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.utils import plot_model\n",
    "# define input sequence\n",
    "sequence = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "# reshape input into [samples, timesteps, features]\n",
    "n_in = len(sequence)\n",
    "sequence = sequence.reshape((1, n_in, 1))\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', input_shape=(n_in,1)))\n",
    "model.add(RepeatVector(n_in))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(sequence, sequence, epochs=300, verbose=0)\n",
    "# connect the encoder LSTM as the output layer\n",
    "model = Model(inputs=model.inputs, outputs=model.layers[0].output)\n",
    "plot_model(model, show_shapes=True, to_file='lstm_encoder.png')\n",
    "# get the feature vector for the input sequence\n",
    "yhat = model.predict(sequence)\n",
    "print(yhat.shape)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
