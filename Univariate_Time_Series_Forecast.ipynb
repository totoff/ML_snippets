{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1841.156\n > 1841.156\n > 1841.156\n > 1841.156\n > 1841.156\n > 1841.156\n > 1841.156\n > 1841.156\n > 1841.156\n > 1841.156\n > 1841.156\n > 1841.156\n > 1841.156\n > 1841.156\n > 1841.156\n > 1841.156\n > 1841.156\n > 1841.156\n > 1841.156\n > 1841.156\n > 1841.156\n > 1841.156\n > 1841.156\n > 1841.156\n > 1841.156\n > 1841.156\n > 1841.156\n > 1841.156\n > 1841.156\n > 1841.156\npersistence: 1841.156 RMSE (+/- 0.000)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# persistence\n",
    "from math import sqrt\n",
    "from numpy import median\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "import os\n",
    "os.chdir(\"C:/Users/LACANAU/Documents/Python Scripts/Machine_Learning_Web\")\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test], data[-n_test:]\n",
    "\n",
    "# transform list into supervised learning format\n",
    "def series_to_supervised(data, n_in=1, n_out=1):\n",
    "    df = DataFrame(data)\n",
    "    cols = list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    # drop rows with NaN values\n",
    "    agg.dropna(inplace=True)\n",
    "    return agg.values\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "    return sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# difference dataset\n",
    "def difference(data, interval):\n",
    "    return [data[i] - data[i - interval] for i in range(interval, len(data))]\n",
    "\n",
    "# fit a model\n",
    "def model_fit(train, config):\n",
    "    return None\n",
    "\n",
    "# forecast with a pre-fit model\n",
    "def model_predict(model, history, config):\n",
    "    values = list()\n",
    "    for offset in config:\n",
    "        values.append(history[-offset])\n",
    "    return median(values)\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "    predictions = list()\n",
    "    # split dataset\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    # fit model\n",
    "    model = model_fit(train, cfg)\n",
    "    # seed history with training dataset\n",
    "    history = [x for x in train]\n",
    "    # step over each time-step in the test set\n",
    "    for i in range(len(test)):\n",
    "        # fit model and make forecast for history\n",
    "        yhat = model_predict(model, history, cfg)\n",
    "        # store forecast in list of predictions\n",
    "        predictions.append(yhat)\n",
    "        # add actual observation to history for the next loop\n",
    "        history.append(test[i])\n",
    "    # estimate prediction error\n",
    "    error = measure_rmse(test, predictions)\n",
    "    print(' > %.3f' % error)\n",
    "    return error\n",
    "\n",
    "# repeat evaluation of a config\n",
    "def repeat_evaluate(data, config, n_test, n_repeats=30):\n",
    "    # fit and evaluate the model n times\n",
    "    scores = [walk_forward_validation(data, n_test, config) for _ in range(n_repeats)]\n",
    "    return scores\n",
    "\n",
    "# summarize model performance\n",
    "def summarize_scores(name, scores):\n",
    "    # print a summary\n",
    "    scores_m, score_std = mean(scores), std(scores)\n",
    "    print('%s: %.3f RMSE (+/- %.3f)' % (name, scores_m, score_std))\n",
    "    # box and whisker plot\n",
    "    pyplot.boxplot(scores)\n",
    "    pyplot.show()\n",
    "\n",
    "series = read_csv('monthly-car-sales.csv', header=0, index_col=0)\n",
    "data = series.values\n",
    "# data split\n",
    "n_test = 12\n",
    "# define config\n",
    "config = [12, 24, 36]\n",
    "# grid search\n",
    "scores = repeat_evaluate(data, config, n_test)\n",
    "# summarize scores\n",
    "summarize_scores('persistence', scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1722.922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1694.405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1551.351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1703.519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1704.008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1420.733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1462.014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1411.786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1637.308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1625.065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1698.102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1807.961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1902.044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1540.508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1400.348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1542.162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1593.787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1575.385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1643.157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1615.332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1658.919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1537.696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1560.787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1951.633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1454.129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1573.917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1441.253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1552.886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1433.775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1791.597\nmlp: 1606.950 RMSE (+/- 138.437)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate mlp\n",
    "from math import sqrt\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test], data[-n_test:]\n",
    "\n",
    "# transform list into supervised learning format\n",
    "def series_to_supervised(data, n_in=1, n_out=1):\n",
    "    df = DataFrame(data)\n",
    "    cols = list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    # drop rows with NaN values\n",
    "    agg.dropna(inplace=True)\n",
    "    return agg.values\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "    return sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# fit a model\n",
    "def model_fit(train, config):\n",
    "    # unpack config\n",
    "    n_input, n_nodes, n_epochs, n_batch = config\n",
    "    # prepare data\n",
    "    data = series_to_supervised(train, n_in=n_input)\n",
    "    train_x, train_y = data[:, :-1], data[:, -1]\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_nodes, activation='relu', input_dim=n_input))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # fit\n",
    "    model.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=0)\n",
    "    return model\n",
    "\n",
    "# forecast with a pre-fit model\n",
    "def model_predict(model, history, config):\n",
    "    # unpack config\n",
    "    n_input, _, _, _ = config\n",
    "    # prepare data\n",
    "    x_input = array(history[-n_input:]).reshape(1, n_input)\n",
    "    # forecast\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "    return yhat[0]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "    predictions = list()\n",
    "    # split dataset\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    # fit model\n",
    "    model = model_fit(train, cfg)\n",
    "    # seed history with training dataset\n",
    "    history = [x for x in train]\n",
    "    # step over each time-step in the test set\n",
    "    for i in range(len(test)):\n",
    "        # fit model and make forecast for history\n",
    "        yhat = model_predict(model, history, cfg)\n",
    "        # store forecast in list of predictions\n",
    "        predictions.append(yhat)\n",
    "        # add actual observation to history for the next loop\n",
    "        history.append(test[i])\n",
    "    # estimate prediction error\n",
    "    error = measure_rmse(test, predictions)\n",
    "    print(' > %.3f' % error)\n",
    "    return error\n",
    "\n",
    "# repeat evaluation of a config\n",
    "def repeat_evaluate(data, config, n_test, n_repeats=30):\n",
    "    # fit and evaluate the model n times\n",
    "    scores = [walk_forward_validation(data, n_test, config) for _ in range(n_repeats)]\n",
    "    return scores\n",
    "\n",
    "# summarize model performance\n",
    "def summarize_scores(name, scores):\n",
    "    # print a summary\n",
    "    scores_m, score_std = mean(scores), std(scores)\n",
    "    print('%s: %.3f RMSE (+/- %.3f)' % (name, scores_m, score_std))\n",
    "    # box and whisker plot\n",
    "    pyplot.boxplot(scores)\n",
    "    pyplot.show()\n",
    "\n",
    "series = read_csv('monthly-car-sales.csv', header=0, index_col=0)\n",
    "data = series.values\n",
    "# data split\n",
    "n_test = 12\n",
    "# define config\n",
    "config = [24, 500, 100, 100]\n",
    "# grid search\n",
    "scores = repeat_evaluate(data, config, n_test)\n",
    "# summarize scores\n",
    "summarize_scores('mlp', scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1580.629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1578.199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1539.112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1482.124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1439.174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1514.601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1521.322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1549.757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1485.565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1580.425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1430.416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1623.179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1508.870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1514.159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1590.758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1610.889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1580.284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1571.369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1570.253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1575.430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1557.237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1544.867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1771.054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1452.013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1597.261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1698.639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1638.974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1601.534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1562.509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1617.310\ncnn: 1562.930 RMSE (+/- 70.579)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate cnn\n",
    "from math import sqrt\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test], data[-n_test:]\n",
    "\n",
    "# transform list into supervised learning format\n",
    "def series_to_supervised(data, n_in=1, n_out=1):\n",
    "    df = DataFrame(data)\n",
    "    cols = list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    # drop rows with NaN values\n",
    "    agg.dropna(inplace=True)\n",
    "    return agg.values\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "    return sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# fit a model\n",
    "def model_fit(train, config):\n",
    "    # unpack config\n",
    "    n_input, n_filters, n_kernel, n_epochs, n_batch = config\n",
    "    # prepare data\n",
    "    data = series_to_supervised(train, n_in=n_input)\n",
    "    train_x, train_y = data[:, :-1], data[:, -1]\n",
    "    train_x = train_x.reshape((train_x.shape[0], train_x.shape[1], 1))\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=n_filters, kernel_size=n_kernel, activation='relu', input_shape=(n_input, 1)))\n",
    "    model.add(Conv1D(filters=n_filters, kernel_size=n_kernel, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # fit\n",
    "    model.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=0)\n",
    "    return model\n",
    "\n",
    "# forecast with a pre-fit model\n",
    "def model_predict(model, history, config):\n",
    "    # unpack config\n",
    "    n_input, _, _, _, _ = config\n",
    "    # prepare data\n",
    "    x_input = array(history[-n_input:]).reshape((1, n_input, 1))\n",
    "    # forecast\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "    return yhat[0]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "    predictions = list()\n",
    "    # split dataset\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    # fit model\n",
    "    model = model_fit(train, cfg)\n",
    "    # seed history with training dataset\n",
    "    history = [x for x in train]\n",
    "    # step over each time-step in the test set\n",
    "    for i in range(len(test)):\n",
    "        # fit model and make forecast for history\n",
    "        yhat = model_predict(model, history, cfg)\n",
    "        # store forecast in list of predictions\n",
    "        predictions.append(yhat)\n",
    "        # add actual observation to history for the next loop\n",
    "        history.append(test[i])\n",
    "    # estimate prediction error\n",
    "    error = measure_rmse(test, predictions)\n",
    "    print(' > %.3f' % error)\n",
    "    return error\n",
    "\n",
    "# repeat evaluation of a config\n",
    "def repeat_evaluate(data, config, n_test, n_repeats=30):\n",
    "    # fit and evaluate the model n times\n",
    "    scores = [walk_forward_validation(data, n_test, config) for _ in range(n_repeats)]\n",
    "    return scores\n",
    "\n",
    "# summarize model performance\n",
    "def summarize_scores(name, scores):\n",
    "    # print a summary\n",
    "    scores_m, score_std = mean(scores), std(scores)\n",
    "    print('%s: %.3f RMSE (+/- %.3f)' % (name, scores_m, score_std))\n",
    "    # box and whisker plot\n",
    "    pyplot.boxplot(scores)\n",
    "    pyplot.show()\n",
    "\n",
    "series = read_csv('monthly-car-sales.csv', header=0, index_col=0)\n",
    "data = series.values\n",
    "# data split\n",
    "n_test = 12\n",
    "# define config\n",
    "config = [36, 256, 3, 100, 100]\n",
    "# grid search\n",
    "scores = repeat_evaluate(data, config, n_test)\n",
    "# summarize scores\n",
    "summarize_scores('cnn', scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2125.932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2164.178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2080.581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2073.377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2152.388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2124.787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2096.948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2019.589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2022.260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2108.455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2202.072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2055.207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2405.339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2327.207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2170.114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2105.257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2100.038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2127.813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2034.058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2154.098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2075.655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2124.966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1938.838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2062.807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2127.083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2128.427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2052.183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2337.826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2165.359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2087.238\nlstm: 2125.003 RMSE (+/- 94.294)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate lstm\n",
    "from math import sqrt\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test], data[-n_test:]\n",
    "\n",
    "# transform list into supervised learning format\n",
    "def series_to_supervised(data, n_in=1, n_out=1):\n",
    "    df = DataFrame(data)\n",
    "    cols = list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    # drop rows with NaN values\n",
    "    agg.dropna(inplace=True)\n",
    "    return agg.values\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "    return sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# difference dataset\n",
    "def difference(data, interval):\n",
    "    return [data[i] - data[i - interval] for i in range(interval, len(data))]\n",
    "\n",
    "# fit a model\n",
    "def model_fit(train, config):\n",
    "    # unpack config\n",
    "    n_input, n_nodes, n_epochs, n_batch, n_diff = config\n",
    "    # prepare data\n",
    "    if n_diff > 0:\n",
    "        train = difference(train, n_diff)\n",
    "    data = series_to_supervised(train, n_in=n_input)\n",
    "    train_x, train_y = data[:, :-1], data[:, -1]\n",
    "    train_x = train_x.reshape((train_x.shape[0], train_x.shape[1], 1))\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_nodes, activation='relu', input_shape=(n_input, 1)))\n",
    "    model.add(Dense(n_nodes, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # fit\n",
    "    model.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=0)\n",
    "    return model\n",
    "\n",
    "# forecast with a pre-fit model\n",
    "def model_predict(model, history, config):\n",
    "    # unpack config\n",
    "    n_input, _, _, _, n_diff = config\n",
    "    # prepare data\n",
    "    correction = 0.0\n",
    "    if n_diff > 0:\n",
    "        correction = history[-n_diff]\n",
    "        history = difference(history, n_diff)\n",
    "    x_input = array(history[-n_input:]).reshape((1, n_input, 1))\n",
    "    # forecast\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "    return correction + yhat[0]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "    predictions = list()\n",
    "    # split dataset\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    # fit model\n",
    "    model = model_fit(train, cfg)\n",
    "    # seed history with training dataset\n",
    "    history = [x for x in train]\n",
    "    # step over each time-step in the test set\n",
    "    for i in range(len(test)):\n",
    "        # fit model and make forecast for history\n",
    "        yhat = model_predict(model, history, cfg)\n",
    "        # store forecast in list of predictions\n",
    "        predictions.append(yhat)\n",
    "        # add actual observation to history for the next loop\n",
    "        history.append(test[i])\n",
    "    # estimate prediction error\n",
    "    error = measure_rmse(test, predictions)\n",
    "    print(' > %.3f' % error)\n",
    "    return error\n",
    "\n",
    "# repeat evaluation of a config\n",
    "def repeat_evaluate(data, config, n_test, n_repeats=30):\n",
    "    # fit and evaluate the model n times\n",
    "    scores = [walk_forward_validation(data, n_test, config) for _ in range(n_repeats)]\n",
    "    return scores\n",
    "\n",
    "# summarize model performance\n",
    "def summarize_scores(name, scores):\n",
    "    # print a summary\n",
    "    scores_m, score_std = mean(scores), std(scores)\n",
    "    print('%s: %.3f RMSE (+/- %.3f)' % (name, scores_m, score_std))\n",
    "    # box and whisker plot\n",
    "    pyplot.boxplot(scores)\n",
    "    pyplot.show()\n",
    "\n",
    "series = read_csv('monthly-car-sales.csv', header=0, index_col=0)\n",
    "data = series.values\n",
    "# data split\n",
    "n_test = 12\n",
    "# define config\n",
    "config = [36, 50, 100, 100, 12]\n",
    "# grid search\n",
    "scores = repeat_evaluate(data, config, n_test)\n",
    "# summarize scores\n",
    "summarize_scores('lstm', scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1577.474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1428.377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1312.515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1699.315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1923.379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1629.671\n"
     ]
    }
   ],
   "source": [
    "# evaluate cnn lstm\n",
    "from math import sqrt\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test], data[-n_test:]\n",
    "\n",
    "# transform list into supervised learning format\n",
    "def series_to_supervised(data, n_in=1, n_out=1):\n",
    "    df = DataFrame(data)\n",
    "    cols = list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    # drop rows with NaN values\n",
    "    agg.dropna(inplace=True)\n",
    "    return agg.values\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "    return sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# fit a model\n",
    "def model_fit(train, config):\n",
    "    # unpack config\n",
    "    n_seq, n_steps, n_filters, n_kernel, n_nodes, n_epochs, n_batch = config\n",
    "    n_input = n_seq * n_steps\n",
    "    # prepare data\n",
    "    data = series_to_supervised(train, n_in=n_input)\n",
    "    train_x, train_y = data[:, :-1], data[:, -1]\n",
    "    train_x = train_x.reshape((train_x.shape[0], n_seq, n_steps, 1))\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=n_filters, kernel_size=n_kernel, activation='relu', input_shape=(None,n_steps,1))))\n",
    "    model.add(TimeDistributed(Conv1D(filters=n_filters, kernel_size=n_kernel, activation='relu')))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(n_nodes, activation='relu'))\n",
    "    model.add(Dense(n_nodes, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # fit\n",
    "    model.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=0)\n",
    "    return model\n",
    "\n",
    "# forecast with a pre-fit model\n",
    "def model_predict(model, history, config):\n",
    "    # unpack config\n",
    "    n_seq, n_steps, _, _, _, _, _ = config\n",
    "    n_input = n_seq * n_steps\n",
    "    # prepare data\n",
    "    x_input = array(history[-n_input:]).reshape((1, n_seq, n_steps, 1))\n",
    "    # forecast\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "    return yhat[0]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "    predictions = list()\n",
    "    # split dataset\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    # fit model\n",
    "    model = model_fit(train, cfg)\n",
    "    # seed history with training dataset\n",
    "    history = [x for x in train]\n",
    "    # step over each time-step in the test set\n",
    "    for i in range(len(test)):\n",
    "        # fit model and make forecast for history\n",
    "        yhat = model_predict(model, history, cfg)\n",
    "        # store forecast in list of predictions\n",
    "        predictions.append(yhat)\n",
    "        # add actual observation to history for the next loop\n",
    "        history.append(test[i])\n",
    "    # estimate prediction error\n",
    "    error = measure_rmse(test, predictions)\n",
    "    print(' > %.3f' % error)\n",
    "    return error\n",
    "\n",
    "# repeat evaluation of a config\n",
    "def repeat_evaluate(data, config, n_test, n_repeats=30):\n",
    "    # fit and evaluate the model n times\n",
    "    scores = [walk_forward_validation(data, n_test, config) for _ in range(n_repeats)]\n",
    "    return scores\n",
    "\n",
    "# summarize model performance\n",
    "def summarize_scores(name, scores):\n",
    "    # print a summary\n",
    "    scores_m, score_std = mean(scores), std(scores)\n",
    "    print('%s: %.3f RMSE (+/- %.3f)' % (name, scores_m, score_std))\n",
    "    # box and whisker plot\n",
    "    pyplot.boxplot(scores)\n",
    "    pyplot.show()\n",
    "\n",
    "series = read_csv('monthly-car-sales.csv', header=0, index_col=0)\n",
    "data = series.values\n",
    "# data split\n",
    "n_test = 12\n",
    "# define config\n",
    "config = [3, 12, 64, 3, 100, 200, 100]\n",
    "# grid search\n",
    "scores = repeat_evaluate(data, config, n_test)\n",
    "# summarize scores\n",
    "summarize_scores('cnn-lstm', scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1960.529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1352.053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1599.564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1747.992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1950.059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1487.604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1886.148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1475.973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1973.874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1921.770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2458.154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1415.352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2428.259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1607.460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1644.022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2102.298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1886.749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1736.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2215.578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1347.501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1445.785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1623.478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2326.845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2378.342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1402.338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1465.594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1596.647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 2158.588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1822.865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 1597.325\nconvlstm: 1800.492 RMSE (+/- 332.403)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate convlstm\n",
    "from math import sqrt\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import ConvLSTM2D\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test], data[-n_test:]\n",
    "\n",
    "# transform list into supervised learning format\n",
    "def series_to_supervised(data, n_in=1, n_out=1):\n",
    "    df = DataFrame(data)\n",
    "    cols = list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    # drop rows with NaN values\n",
    "    agg.dropna(inplace=True)\n",
    "    return agg.values\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "    return sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# difference dataset\n",
    "def difference(data, interval):\n",
    "    return [data[i] - data[i - interval] for i in range(interval, len(data))]\n",
    "\n",
    "# fit a model\n",
    "def model_fit(train, config):\n",
    "    # unpack config\n",
    "    n_seq, n_steps, n_filters, n_kernel, n_nodes, n_epochs, n_batch = config\n",
    "    n_input = n_seq * n_steps\n",
    "    # prepare data\n",
    "    data = series_to_supervised(train, n_in=n_input)\n",
    "    train_x, train_y = data[:, :-1], data[:, -1]\n",
    "    train_x = train_x.reshape((train_x.shape[0], n_seq, 1, n_steps, 1))\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(ConvLSTM2D(filters=n_filters, kernel_size=(1,n_kernel), activation='relu', input_shape=(n_seq, 1, n_steps, 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_nodes, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # fit\n",
    "    model.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=0)\n",
    "    return model\n",
    "\n",
    "# forecast with a pre-fit model\n",
    "def model_predict(model, history, config):\n",
    "    # unpack config\n",
    "    n_seq, n_steps, _, _, _, _, _ = config\n",
    "    n_input = n_seq * n_steps\n",
    "    # prepare data\n",
    "    x_input = array(history[-n_input:]).reshape((1, n_seq, 1, n_steps, 1))\n",
    "    # forecast\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "    return yhat[0]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "    predictions = list()\n",
    "    # split dataset\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    # fit model\n",
    "    model = model_fit(train, cfg)\n",
    "    # seed history with training dataset\n",
    "    history = [x for x in train]\n",
    "    # step over each time-step in the test set\n",
    "    for i in range(len(test)):\n",
    "        # fit model and make forecast for history\n",
    "        yhat = model_predict(model, history, cfg)\n",
    "        # store forecast in list of predictions\n",
    "        predictions.append(yhat)\n",
    "        # add actual observation to history for the next loop\n",
    "        history.append(test[i])\n",
    "    # estimate prediction error\n",
    "    error = measure_rmse(test, predictions)\n",
    "    print(' > %.3f' % error)\n",
    "    return error\n",
    "\n",
    "# repeat evaluation of a config\n",
    "def repeat_evaluate(data, config, n_test, n_repeats=30):\n",
    "    # fit and evaluate the model n times\n",
    "    scores = [walk_forward_validation(data, n_test, config) for _ in range(n_repeats)]\n",
    "    return scores\n",
    "\n",
    "# summarize model performance\n",
    "def summarize_scores(name, scores):\n",
    "    # print a summary\n",
    "    scores_m, score_std = mean(scores), std(scores)\n",
    "    print('%s: %.3f RMSE (+/- %.3f)' % (name, scores_m, score_std))\n",
    "    # box and whisker plot\n",
    "    pyplot.boxplot(scores)\n",
    "    pyplot.show()\n",
    "\n",
    "series = read_csv('monthly-car-sales.csv', header=0, index_col=0)\n",
    "data = series.values\n",
    "# data split\n",
    "n_test = 12\n",
    "# define config\n",
    "config = [3, 12, 256, 3, 200, 200, 100]\n",
    "# grid search\n",
    "scores = repeat_evaluate(data, config, n_test)\n",
    "# summarize scores\n",
    "summarize_scores('convlstm', scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
